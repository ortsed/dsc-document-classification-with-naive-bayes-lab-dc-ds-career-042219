{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lecture, you'll practice implementing the Naive Bayes algorithm on your own.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:  \n",
    "\n",
    "* Implement document classification using naive Bayes\n",
    "* Understand the need for the Laplacian smoothing correction\n",
    "* Explain how to code a bag of words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset\n",
    "\n",
    "To start, import the dataset stored in the text file `SMSSpamCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md  index.ipynb  LICENSE.md  README.md  SMSSpamCollection\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SMSSpamCollection\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for Class Imbalance\n",
    "\n",
    "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ham  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4  spam   \n",
       "\n",
       "  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "0                      Ok lar... Joking wif u oni...                                                               \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...                                                               \n",
       "2  U dun say so early hor... U c already then say...                                                               \n",
       "3  Nah I don't think he goes to usf, he lives aro...                                                               \n",
       "4  FreeMsg Hey there darling it's been 3 week's n...                                                               "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df[df[\"ham\"] == \"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = df[df[\"ham\"] == \"ham\"][0:747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df_spam, df_ham])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = [\"ham\", \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split\n",
    "\n",
    "Now implement a train test split on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2[\"text\"], df2[\"ham\"], test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word frequency dictionary for each class\n",
    "\n",
    "Create a word frequency dictionary for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ham = X_train[y_train == \"ham\"]\n",
    "X_train_spam = X_train[y_train == \"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246              I asked you to call him now ok\n",
       "720               Oh is it? Send me the address\n",
       "222                      Sorry, I'll call later\n",
       "111             Going for dinner.msg you after.\n",
       "110    What is the plural of the noun research?\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_words_ham = \"\"\n",
    "for row in X_train_ham:\n",
    "    all_words_ham += \" \" + row\n",
    "all_words_ham = all_words_ham.split(\" \")\n",
    "all_ham = Counter(all_words_ham)\n",
    "\n",
    "all_words_spam = \"\"\n",
    "for row in X_train_spam:\n",
    "    all_words_spam += \" \" + row\n",
    "all_words_spam = all_words_spam.split(\" \")\n",
    "all_spam = Counter(all_words_spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Total Corpus Words\n",
    "Calculate V, the total number of words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count = len(all_words_spam) + len(all_words_ham)\n",
    "all_words = Counter(all_words_spam + all_words_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bag of Words Function\n",
    "\n",
    "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes\n",
    "\n",
    "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13908"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_spam.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_spam_probs = {}\n",
    "for k,v in all_words.items():\n",
    "    if k:\n",
    "        if k in all_spam:\n",
    "            num = (all_spam[k] + 1)\n",
    "            den = sum(all_spam.values()) + sum(all_words.values())\n",
    "            all_spam_probs[k] =num/den\n",
    "        else:\n",
    "            all_spam_probs[k] = 1/sum(all_spam.values()) + sum(all_words.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_ham_probs = {}\n",
    "for k,v in all_words.items():\n",
    "    if k:\n",
    "        if k in all_ham:\n",
    "            num = (all_ham[k] + 1)\n",
    "            den = sum(all_ham.values()) + sum(all_words.values())\n",
    "            all_ham_probs[k] =num/den\n",
    "        else:\n",
    "            all_ham_probs[k] = 1/sum(all_ham.values()) + sum(all_words.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out Your Classifier\n",
    "\n",
    "Finally, test out your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(words):\n",
    "    ham_spam = [0,0]\n",
    "    for word in words.split(\" \"):\n",
    "        ham_prob = all_ham_probs[k]\n",
    "        spam_prob = all_spam_probs[k]\n",
    "        ham_spam[0] *= ham_prob\n",
    "        ham_spam[1] *= spam_prob\n",
    "    if ham_spam[0] > ham_spam[1]:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"spam\"\n",
    "    \n",
    "classify(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up\n",
    "\n",
    "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you practiced implementing naive Bayes' for document classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
